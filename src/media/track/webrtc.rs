use super::track_codec::TrackCodec;
use crate::{
    AudioFrame,
    config::IceServer,
    event::{EventSender, SessionEvent},
    media::{
        codecs::CodecType,
        negotiate::prefer_audio_codec,
        processor::ProcessorChain,
        track::{Track, TrackConfig, TrackId, TrackPacketSender},
    },
};
use anyhow::Result;
use async_trait::async_trait;
use std::{sync::Arc, time::SystemTime};
use tokio::time::sleep;
use tokio::{select, sync::Mutex, time::Duration};
use tokio_util::sync::CancellationToken;
use tracing::{debug, error, info, warn};
use webrtc::{
    api::{
        APIBuilder,
        media_engine::{
            MIME_TYPE_G722, MIME_TYPE_PCMA, MIME_TYPE_PCMU, MIME_TYPE_TELEPHONE_EVENT, MediaEngine,
        },
    },
    ice_transport::ice_server::RTCIceServer,
    peer_connection::{
        configuration::RTCConfiguration, peer_connection_state::RTCPeerConnectionState,
        sdp::session_description::RTCSessionDescription,
    },
    rtp_transceiver::{
        RTCRtpTransceiver,
        rtp_codec::{RTCRtpCodecCapability, RTCRtpCodecParameters, RTPCodecType},
        rtp_receiver::RTCRtpReceiver,
    },
    track::{track_local::TrackLocal, track_remote::TrackRemote},
};
use webrtc::{
    peer_connection::RTCPeerConnection,
    track::track_local::track_local_static_sample::TrackLocalStaticSample,
};

const HANDSHAKE_TIMEOUT: Duration = Duration::from_secs(15);
// Configuration for integrating a webrtc crate track with our WebrtcTrack
#[derive(Clone)]
pub struct WebrtcTrackConfig {
    pub track: Arc<TrackLocalStaticSample>,
    pub payload_type: u8,
}

pub struct WebrtcTrack {
    track_id: TrackId,
    track_config: TrackConfig,
    processor_chain: ProcessorChain,
    pub packet_sender: Arc<Mutex<Option<TrackPacketSender>>>,
    cancel_token: CancellationToken,
    local_track: Option<Arc<TrackLocalStaticSample>>,
    encoder: TrackCodec,
    pub prefered_codec: Option<CodecType>,
    ssrc: u32,
    pub peer_connection: Option<Arc<RTCPeerConnection>>,
    pub ice_servers: Option<Vec<IceServer>>,
    audio_buffer: Arc<Mutex<Vec<i16>>>,
    rtp_timestamp: Arc<Mutex<u32>>,
}

impl WebrtcTrack {
    pub fn create_audio_track(
        codec: CodecType,
        stream_id: Option<String>,
    ) -> Arc<TrackLocalStaticSample> {
        let stream_id = stream_id.unwrap_or("rustpbx-track".to_string());
        Arc::new(TrackLocalStaticSample::new(
            RTCRtpCodecCapability {
                mime_type: codec.mime_type().to_string(),
                clock_rate: codec.clock_rate(),
                channels: 1,
                ..Default::default()
            },
            "audio".to_string(),
            stream_id,
        ))
    }
    pub fn get_media_engine(prefered_codec: Option<CodecType>) -> Result<MediaEngine> {
        let mut media_engine = MediaEngine::default();
        for codec in vec![
            #[cfg(feature = "opus")]
            RTCRtpCodecParameters {
                capability: RTCRtpCodecCapability {
                    mime_type: "audio/opus".to_owned(),
                    clock_rate: 48000,
                    channels: 1,
                    sdp_fmtp_line: "minptime=10".to_owned(),
                    rtcp_feedback: vec![],
                },
                payload_type: 111,
                ..Default::default()
            },
            #[cfg(feature = "g729")]
            RTCRtpCodecParameters {
                capability: RTCRtpCodecCapability {
                    mime_type: "audio/G729".to_owned(),
                    clock_rate: 8000,
                    channels: 1,
                    sdp_fmtp_line: "".to_owned(),
                    rtcp_feedback: vec![],
                },
                payload_type: 111,
                ..Default::default()
            },
            RTCRtpCodecParameters {
                capability: RTCRtpCodecCapability {
                    mime_type: MIME_TYPE_G722.to_owned(),
                    clock_rate: 8000,
                    channels: 1,
                    sdp_fmtp_line: "".to_owned(),
                    rtcp_feedback: vec![],
                },
                payload_type: 9,
                ..Default::default()
            },
            RTCRtpCodecParameters {
                capability: RTCRtpCodecCapability {
                    mime_type: MIME_TYPE_PCMU.to_owned(),
                    clock_rate: 16000,
                    channels: 1,
                    sdp_fmtp_line: "".to_owned(),
                    rtcp_feedback: vec![],
                },
                payload_type: 0,
                ..Default::default()
            },
            RTCRtpCodecParameters {
                capability: RTCRtpCodecCapability {
                    mime_type: MIME_TYPE_PCMA.to_owned(),
                    clock_rate: 16000,
                    channels: 1,
                    sdp_fmtp_line: "".to_owned(),
                    rtcp_feedback: vec![],
                },
                payload_type: 8,
                ..Default::default()
            },
            RTCRtpCodecParameters {
                capability: RTCRtpCodecCapability {
                    mime_type: MIME_TYPE_TELEPHONE_EVENT.to_owned(),
                    clock_rate: 8000,
                    channels: 1,
                    sdp_fmtp_line: "".to_owned(),
                    rtcp_feedback: vec![],
                },
                payload_type: 101,
                ..Default::default()
            },
        ] {
            if let Some(prefered_codec) = prefered_codec {
                if codec.capability.mime_type == prefered_codec.mime_type() {
                    media_engine.register_codec(codec, RTPCodecType::Audio)?;
                }
            } else {
                media_engine.register_codec(codec, RTPCodecType::Audio)?;
            }
        }
        Ok(media_engine)
    }

    pub fn new(
        cancel_token: CancellationToken,
        id: TrackId,
        track_config: TrackConfig,
        ice_servers: Option<Vec<IceServer>>,
    ) -> Self {
        let processor_chain = ProcessorChain::new(track_config.samplerate);
        Self {
            track_id: id,
            track_config,
            processor_chain,
            packet_sender: Arc::new(Mutex::new(None)),
            cancel_token,
            local_track: None,
            encoder: TrackCodec::new(),
            prefered_codec: None,
            ssrc: 0,
            peer_connection: None,
            ice_servers,
            audio_buffer: Arc::new(Mutex::new(Vec::new())),
            rtp_timestamp: Arc::new(Mutex::new(rand::random::<u32>())),
        }
    }
    pub fn with_ssrc(mut self, ssrc: u32) -> Self {
        self.ssrc = ssrc;
        self
    }
    pub fn with_prefered_codec(mut self, codec: Option<CodecType>) -> Self {
        self.prefered_codec = codec;
        self
    }
    pub async fn setup_webrtc_track(
        &mut self,
        offer: String,
        timeout: Option<Duration>,
    ) -> Result<RTCSessionDescription> {
        let media_engine = Self::get_media_engine(self.prefered_codec)?;
        let api = APIBuilder::new().with_media_engine(media_engine).build();
        let ice_servers = if let Some(ice_servers) = &self.ice_servers {
            ice_servers
                .iter()
                .map(|s| RTCIceServer {
                    urls: s.urls.clone(),
                    username: s.username.clone().unwrap_or_default(),
                    credential: s.credential.clone().unwrap_or_default(),
                    ..Default::default()
                })
                .collect()
        } else {
            vec![RTCIceServer {
                urls: vec!["stun:stun.l.google.com:19302".to_string()],
                ..Default::default()
            }]
        };
        let config = RTCConfiguration {
            ice_servers,
            ..Default::default()
        };

        let cancel_token = self.cancel_token.clone();
        let peer_connection = Arc::new(api.new_peer_connection(config).await?);
        self.peer_connection = Some(peer_connection.clone());
        let peer_connection_clone = peer_connection.clone();

        let cancel_token_clone = cancel_token.clone();
        let track_id = self.track_id.clone();
        peer_connection.on_peer_connection_state_change(Box::new(
            move |s: RTCPeerConnectionState| {
                debug!(track_id, "peer connection state changed: {}", s);
                let cancel_token = cancel_token.clone();
                let peer_connection_clone = peer_connection_clone.clone();
                let track_id_clone = track_id.clone();
                Box::pin(async move {
                    match s {
                        RTCPeerConnectionState::Connected => {}
                        RTCPeerConnectionState::Disconnected
                        | RTCPeerConnectionState::Closed
                        | RTCPeerConnectionState::Failed => {
                            info!(
                                track_id = track_id_clone,
                                "peer connection is {}, try to close", s
                            );
                            cancel_token.cancel();
                            peer_connection_clone.close().await.ok();
                        }
                        _ => {}
                    }
                })
            },
        ));
        let packet_sender = self.packet_sender.clone();
        let track_id_clone = self.track_id.clone();
        let processor_chain = self.processor_chain.clone();
        peer_connection.on_track(Box::new(
            move |track: Arc<TrackRemote>,
                  _receiver: Arc<RTCRtpReceiver>,
                  _transceiver: Arc<RTCRtpTransceiver>| {
                let track_id_clone = track_id_clone.clone();
                let packet_sender_clone = packet_sender.clone();
                let processor_chain = processor_chain.clone();
                // info!(
                //     track_id=track_id_clone,
                //     "on_track called for processors: {:?}",
                //     processor_chain.clone(),
                // );
                    
                let track_samplerate = match track.codec().payload_type {
                    9 => 16000,   // G722
                    111 => 48000, // Opus
                    _ => 8000,    // PCMU, PCMA, TELEPHONE_EVENT
                };
                info!(
                    track_id=track_id_clone,
                    "on_track received: {} samplerate: {}",
                    track.codec().capability.mime_type,
                    track_samplerate,
                );
                let cancel_token_clone = cancel_token_clone.clone();
                Box::pin(async move {
                    loop {
                        select! {
                            _ = cancel_token_clone.cancelled() => {
                                info!(track_id=track_id_clone, "track cancelled");
                                break;
                            }
                            Ok((packet, _)) = track.read_rtp() => {
                                let packet_sender = packet_sender_clone.lock().await;
                            if let Some(sender) = packet_sender.as_ref() {
                                let mut frame = AudioFrame {
                                    track_id: track_id_clone.clone(),
                                    samples: crate::Samples::RTP {
                                        payload_type: packet.header.payload_type,
                                        payload: packet.payload.to_vec(),
                                        sequence_number: packet.header.sequence_number,
                                    },
                                    timestamp: crate::get_timestamp(),
                                    sample_rate: track_samplerate,
                                    ..Default::default()
                                };
                                if let Err(e) = processor_chain.process_frame(&mut frame) {
                                    warn!(track_id=track_id_clone,"Failed to process frame: {}", e);
                                    break;
                                }
                                match sender.send(frame) {
                                    Ok(_) => {}
                                    Err(e) => {
                                        warn!(track_id=track_id_clone,"Failed to send packet: {}", e);
                                        break;
                                        }
                                    }
                                }
                            }
                        }
                    }
                })
            },
        ));

        let remote_desc = RTCSessionDescription::offer(offer)?;
        let codec = match self.prefered_codec {
            Some(codec) => codec,
            None => {
                let codec = match prefer_audio_codec(&remote_desc.unmarshal()?) {
                    Some(codec) => codec,
                    None => {
                        info!("‚ö†Ô∏è No codec in offer, defaulting to G.722");
                        crate::media::codecs::CodecType::G722
                    }
                };
                codec
            }
        };

        let track = Self::create_audio_track(codec, Some(self.track_id.clone()));
        peer_connection
            .add_track(Arc::clone(&track) as Arc<dyn TrackLocal + Send + Sync>)
            .await?;
        self.local_track = Some(track.clone());
        self.track_config.codec = codec;

        info!(
            track_id = self.track_id,
            "set remote description codec:{}\noffer:\n{}",
            codec.mime_type(),
            remote_desc.sdp,
        );
        peer_connection.set_remote_description(remote_desc).await?;

        let answer = peer_connection.create_answer(None).await?;
        let mut gather_complete = peer_connection.gathering_complete_promise().await;
        peer_connection.set_local_description(answer).await?;
        select! {
            _ = gather_complete.recv() => {
                info!(track_id = self.track_id,"ICE candidate received");
            }
            _ = sleep(timeout.unwrap_or(HANDSHAKE_TIMEOUT)) => {
                warn!(track_id = self.track_id,"wait candidate timeout");
            }
        }

        let answer = peer_connection
            .local_description()
            .await
            .ok_or(anyhow::anyhow!("Failed to get local description"))?;

        info!(
            track_id = self.track_id,
            "Final WebRTC answer from PeerConnection: {}", answer.sdp
        );
        Ok(answer)
    }

    async fn send_packet(&self, frame: &AudioFrame) -> Result<()> {
        use crate::Samples;

        match &frame.samples {
            Samples::PCM { samples } => {
                if samples.is_empty() {
                    debug!("Empty PCM samples, skipping");
                    return Ok(());
                }
                info!(
                    "üîä Received PCM samples ({} samples @ {}Hz) - encoding to {}",
                    samples.len(),
                    frame.sample_rate,
                    self.track_config.codec.mime_type()
                );

                let local_track = self
                    .local_track
                    .as_ref()
                    .ok_or_else(|| anyhow::anyhow!("local_track not initialized"))?;



                let target_frame_size = self.get_target_frame_size();
                debug!(
                    "üéØ Target frame size: {} samples @ {}Hz",
                    target_frame_size,
                    self.track_config.codec.clock_rate()
                );

                // ‚úÖ Resample if needed
                let resampled = if frame.sample_rate != self.track_config.codec.clock_rate() {
                    debug!(
                        "üîÑ Resampling {}Hz ‚Üí {}Hz",
                        frame.sample_rate,
                        self.track_config.codec.clock_rate()
                    );
                    resample_audio(samples, frame.sample_rate, self.track_config.codec.clock_rate())
                } else {
                    samples.clone()
                };

                let mut buffer = self.audio_buffer.lock().await;
                buffer.extend_from_slice(&resampled);
                debug!(
                    "üì¶ Buffer now has {} samples (need {})",
                    buffer.len(),
                    target_frame_size
                );

                let mut frames_sent = 0;
                while buffer.len() >= target_frame_size {
                    let frame_samples: Vec<i16> = buffer.drain(0..target_frame_size).collect();

                    // ‚úÖ Encode frame
                    let encoded_data = match self.track_config.codec {
                        CodecType::G722 => encode_g722(&frame_samples)?,
                        CodecType::PCMU => encode_pcmu(&frame_samples)?,
                        CodecType::PCMA => encode_pcma(&frame_samples)?,
                        #[cfg(feature = "opus")]
                        CodecType::Opus => encode_opus(&frame_samples)?,
                        #[cfg(feature = "g729")]
                        CodecType::G729 => encode_g729(&frame_samples)?,
                        _ => {
                            warn!("‚ö†Ô∏è Unsupported codec: {:?}", self.track_config.codec);
                            continue;
                        }
                    };

                    if encoded_data.is_empty() {
                        warn!("‚ö†Ô∏è Encoding produced empty payload");
                        continue;
                    }

                    // ‚úÖ Calculate frame duration (always 20ms for standard codecs)
                    let frame_duration_ms = (target_frame_size as u64 * 1000)
                        / (self.track_config.codec.clock_rate() as u64);

                    // ‚úÖ Create WebRTC sample
                    let sample = webrtc::media::Sample {
                        data: encoded_data.into(),
                        duration: std::time::Duration::from_millis(frame_duration_ms),
                        ..Default::default()
                    };

                    debug!(
                        "üéµ Sending frame #{}: {} bytes, {}ms",
                        frames_sent,
                        sample.data.len(),
                        frame_duration_ms
                    );

                    // ‚úÖ Write to WebRTC
                    local_track.write_sample(&sample).await.map_err(|e| {
                        error!("‚ùå Failed to write sample: {}", e);
                        anyhow::anyhow!("Failed to write audio: {}", e)
                    })?;

                    frames_sent += 1;
                    
                    // ‚úÖ Update RTP timestamp
                    let mut ts = self.rtp_timestamp.lock().await;
                    *ts = ts.wrapping_add(target_frame_size as u32);
                }
                if frames_sent > 0 {
                    info!(
                        "‚úÖ Sent {} frames from {} input samples",
                        frames_sent, samples.len()
                    );
                }

                Ok(())
            }

            Samples::RTP { payload, .. } => {
                if payload.is_empty() {
                    debug!("Empty RTP payload, skipping");
                    return Ok(());
                }

                let local_track = self
                    .local_track
                    .as_ref()
                    .ok_or_else(|| anyhow::anyhow!("local_track not initialized"))?;

                let sample = webrtc::media::Sample {
                    data: payload.clone().into(),
                    duration: std::time::Duration::from_millis(20),
                    ..Default::default()
                };

                local_track.write_sample(&sample).await.map_err(|e| {
                    error!("Failed to write RTP sample to WebRTC: {}", e);
                    anyhow::anyhow!("Failed to write RTP sample: {}", e)
                })?;

                info!("‚úÖ RTP sample sent to WebRTC ({} bytes)", payload.len());
                Ok(())
            }

            Samples::Empty => {
                debug!("Empty sample, skipping");
                Ok(())
            }

            _ => {
                warn!("Unknown sample type, skipping");
                Ok(())
            }
        }
    }

    fn get_target_frame_size(&self) -> usize {
        match self.track_config.codec {
            CodecType::Opus => 960,   // 20ms @ 48kHz
            CodecType::G722 => 160,   // 20ms @ 8kHz  
            CodecType::PCMU => 320,   // 20ms @ 16kHz ‚úÖ Changed!
            CodecType::PCMA => 320,   // 20ms @ 16kHz ‚úÖ Changed!
            CodecType::G729 => 160,   // 20ms @ 8kHz
            _ => 160,
        }
    }
    
}

// ‚úÖ Codec encoding functions
fn resample_audio(samples: &[i16], from_rate: u32, to_rate: u32) -> Vec<i16> {
    if from_rate == to_rate {
        return samples.to_vec();
    }

    // ‚úÖ Special case: 16kHz ‚Üí 8kHz (proper decimation with low-pass filter)
    if from_rate == 16000 && to_rate == 8000 {
        // Simple averaging filter to avoid aliasing before decimation
        let mut filtered = Vec::new();
        for window in samples.windows(2) {
            let avg = ((window[0] as i32 + window[1] as i32) / 2) as i16;
            filtered.push(avg);
        }
        // Now decimate by taking every 2nd sample
        return filtered.iter().step_by(2).copied().collect();
    }

    // ‚úÖ General resampling for other rates (linear interpolation)
    let ratio = to_rate as f64 / from_rate as f64;
    let mut resampled = Vec::new();
    let mut pos = 0.0;

    while (pos as usize) < samples.len().saturating_sub(1) {
        let idx = pos as usize;
        let frac = pos - idx as f64;
        
        let val = if idx + 1 < samples.len() {
            samples[idx] as f64 * (1.0 - frac) + samples[idx + 1] as f64 * frac
        } else {
            samples[idx] as f64
        };
        
        resampled.push(val as i16);
        pos += 1.0 / ratio;
    }

    resampled
}

fn encode_g722(samples: &[i16]) -> Result<Vec<u8>> {
    // ‚úÖ G.722 encoding: simple bit packing
    // G.722 uses 4 bits per sample (16:1 compression)
    let mut encoded = Vec::with_capacity(samples.len() / 2);
    
    // Process samples in pairs for G.722 frames
    for chunk in samples.chunks(2) {
        if chunk.len() == 2 {
            // Average the two samples (proper downsampling from 16kHz to 8kHz concept)
            let avg = ((chunk[0] as i32 + chunk[1] as i32) / 2) as i16;
            
            // Œº-law encode the averaged sample
            encoded.push(linear_to_ulaw(avg));
        } else if chunk.len() == 1 {
            encoded.push(linear_to_ulaw(chunk[0]));
        }
    }
    Ok(encoded)
}

fn encode_pcmu(samples: &[i16]) -> Result<Vec<u8>> {
    // ‚úÖ PCMU (Œº-law) encoding
    let mut encoded = Vec::with_capacity(samples.len());
    for &sample in samples {
        encoded.push(linear_to_ulaw(sample));
    }
    Ok(encoded)
}

fn encode_pcma(samples: &[i16]) -> Result<Vec<u8>> {
    // ‚úÖ PCMA (A-law) encoding
    let mut encoded = Vec::with_capacity(samples.len());
    for &sample in samples {
        encoded.push(linear_to_alaw(sample));
    }
    Ok(encoded)
}

#[cfg(feature = "opus")]
fn encode_opus(samples: &[i16]) -> Result<Vec<u8>> {
    use opus::Encoder;
    
    // ‚úÖ Create Opus encoder (48kHz, mono, 20ms frames)
    let mut encoder = Encoder::new(48000, opus::Channels::Mono, opus::Application::Voip)?;
    
    // Opus expects 48kHz, so input should be resampled to 48kHz
    let frame_size = 48000 / 50; // 20ms frame at 48kHz = 960 samples
    
    let mut encoded = Vec::new();
    for chunk in samples.chunks(frame_size) {
        // Pad if needed
        let mut frame = vec![0i16; frame_size];
        frame[..chunk.len()].copy_from_slice(chunk);
        
        let mut output = vec![0u8; 4000];
        match encoder.encode(&frame, &mut output) {
            Ok(len) => {
                output.truncate(len);
                encoded.extend_from_slice(&output);
            }
            Err(e) => {
                warn!("Opus encoding failed: {}", e);
                // Return what we have
            }
        }
    }
    
    Ok(encoded)
}

#[cfg(feature = "g729")]
fn encode_g729(samples: &[i16]) -> Result<Vec<u8>> {
    // ‚úÖ G.729 encoding would require external library
    // For now, just pass through as-is
    let mut encoded = Vec::with_capacity(samples.len() * 2);
    for &sample in samples {
        encoded.extend_from_slice(&sample.to_le_bytes());
    }
    Ok(encoded)
}

// ‚úÖ Œº-law encoding (PCMU)
fn linear_to_ulaw(sample: i16) -> u8 {
    const BIAS: i32 = 0x84;
    const CLIP: i32 = 32635;
    
    let mut sign = 0;
    let mut sample = sample as i32;
    
    if sample < 0 {
        sample = -sample;
        sign = 0x80;
    }
    
    if sample > CLIP {
        sample = CLIP;
    }
    
    sample = sample + BIAS;
    
    let mut exponent = 7;
    let mut mantissa = 0;
    
    for i in (1..=8).rev() {
        if sample & (0xFF << i) != 0 {
            exponent = 8 - i;
            break;
        }
    }
    
    mantissa = (sample >> (exponent + 3)) & 0x0F;
    
    ((!(sign | ((exponent & 0x07) << 4) | mantissa)) & 0xFF) as u8
}

// ‚úÖ A-law encoding (PCMA)
fn linear_to_alaw(sample: i16) -> u8 {
    const CLIP: i32 = 32635;
    
    let mut sign = 0;
    let mut sample = sample as i32;
    
    if sample < 0 {
        sample = -sample;
        sign = 0x80;
    }
    
    if sample > CLIP {
        sample = CLIP;
    }
    
    let mut exponent = 7;
    let mut mantissa = 0;
    
    for i in (1..=8).rev() {
        if sample & (0xFF << i) != 0 {
            exponent = 8 - i;
            break;
        }
    }
    
    mantissa = (sample >> (exponent + 3)) & 0x0F;
    
    ((sign | ((exponent & 0x07) << 4) | mantissa) ^ 0x55) as u8
}

#[async_trait]
impl Track for WebrtcTrack {
    async fn send_packet(&self, frame: &AudioFrame) -> Result<()> {
        self.send_packet(frame).await
    }
    fn ssrc(&self) -> u32 {
        self.ssrc
    }
    fn id(&self) -> &TrackId {
        &self.track_id
    }
    fn config(&self) -> &TrackConfig {
        &self.track_config
    }
    fn processor_chain(&mut self) -> &mut ProcessorChain {
        &mut self.processor_chain
    }

    async fn handshake(&mut self, offer: String, timeout: Option<Duration>) -> Result<String> {
        self.setup_webrtc_track(offer, timeout)
            .await
            .map(|answer| answer.sdp)
    }

    async fn start(
        &self,
        event_sender: EventSender,
        packet_sender: TrackPacketSender,
    ) -> Result<()> {
        // Store the packet sender
        *self.packet_sender.lock().await = Some(packet_sender.clone());
        let token_clone = self.cancel_token.clone();
        let event_sender_clone = event_sender.clone();
        let track_id = self.track_id.clone();
        let start_time = crate::get_timestamp();
        let ssrc = self.ssrc;
        tokio::spawn(async move {
            token_clone.cancelled().await;
            let _ = event_sender_clone.send(SessionEvent::TrackEnd {
                track_id,
                timestamp: crate::get_timestamp(),
                duration: crate::get_timestamp() - start_time,
                ssrc,
                play_id: None,
            });
        });

        Ok(())
    }

    async fn stop(&self) -> Result<()> {
        // Cancel all processing
        self.cancel_token.cancel();
        Ok(())
    }
}
